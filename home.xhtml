<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title>home</title>
</head>
<body>

<h1 style="text-align:center;font-size:40px">LET'S DIVE INTO TECHNOLOGY</h1>

<h2 id="para1">MACHINE LEARNING</h2>
<img src="ml.jpeg" alt="ai"  width="350" breaduth="350"/>
<p>A wave of obsession for all-things machine learning (ML) has washed over the technology and business communities — and society more broadly — in the last several years, and understandably so; machine learning-enabled products and services can present myriad benefits to an organization — not least the ability to harness large swaths of data to make previously tedious tasks more easy and efficient.
    Having a solid foundation for real-world ML is a major determinant of success for new initiatives, and is an exciting area of research and engineering in its own right, but the implementation of ML can even be challenging for organizations with mature engineering strength, and it goes without saying that there can be pitfalls and misconceptions in attempts to make the jump between machine learning research and ML in production environments. A frequently overshadowed and often under-appreciated aspect of getting it right is the infrastructure that enables robust, well-managed research and serves customers in production applications.
    A key lever in setting the foundation for a successful ML program is building a culture and an atmosphere that allows you to trial these efforts at scale: accelerating the rate of scientific experimentation on the road to production and, ultimately, to business value. The cloud is an integral part of these efforts, and it can enable teams to develop and deploy well-governed, accurate ML models to high-volume production environments. Beyond production deployments, a solid infrastructure paves the way for large-scale testing of models and frameworks, allows for greater exploration of the interactions of deep learning tools, and enables teams to rapidly onboard new developers and ensure that future model changes do not have masked effects.
    Here, I’ll outline some tactical and procedural guidelines for setting the foundation to bring effective machine learning to production across your enterprise through automated model integration/deployment (MI/MD).
</p>

<h2 id="para2">ARTICIFIAL INTELLIGENCE</h2>
<img src="ai.jpg" alt="ai"  width="350" breaduth="350"/>
 <p>
  
  Less than a decade after breaking the Nazi encryption machine Enigma and helping the Allied Forces win World War II, mathematician Alan Turing changed history a second time with a simple question: "Can machines think?" 

  Turing's paper "Computing Machinery and Intelligence" (1950), and it's subsequent Turing Test, established the fundamental goal and vision of artificial intelligence.   
  
  what is artificial intelligenceAt it's core, AI is the branch of computer science that aims to answer Turing's question in the affirmative. It is the endeavor to replicate or simulate human intelligence in machines.
  
  The expansive goal of artificial intelligence has given rise to many questions and debates. So much so, that no singular definition of the field is universally accepted.  
  
  The major limitation in defining AI as simply "building machines that are intelligent" is that it doesn't actually explain what artificial intelligence is? What makes a machine intelligent?
  
  In their groundbreaking textbook Artificial Intelligence: A Modern Approach, authors Stuart Russell and Peter Norvig approach the question by unifying their work around the theme of intelligent agents in machines. With this in mind, AI is "the study of agents that receive percepts from the environment and perform actions." (Russel and Norvig viii)
  
  Norvig and Russell go on to explore four different approaches that have historically defined the field of AI: Thinking humanlyThinking rationallyActing humanly Acting rationally
  The first two ideas concern thought processes and reasoning, while the others deal with behavior. Norvig and Russell focus particularly on rational agents that act to achieve the best outcome, noting "all the skills needed for the Turing Test also allow an agent to act rationally." (Russel and Norvig 4).
  Patrick Winston, the Ford professor of artificial intelligence and computer science at MIT, defines AI as  "algorithms enabled by constraints, exposed by representations that support models targeted at loops that tie thinking, perception and action together."

</p>

<h2 id="para3">DATA MINING</h2>
<img src="dm.png" alt="ai"  width="350" breaduth="350"/>
 <p>
  Data Mining is a set of method that applies to large and complex databases. This is to eliminate the randomness and 
  discover the hidden pattern. As these data mining methods are almost always computationally intensive. We use
   data mining tools, methodologies, and theories for revealing patterns in data. There are 
   too many driving forces present. And, this is the reason why data mining has become such an important area of study.
   In 1960s statisticians used the terms “Data Fishing” or “Data Dredging”. That was to refer what they considered the bad practice of analyzing data. The term “Data Mining” appeared around 1990 in the database community.
   We use data mining techniques for a long process of research and product development. As this evolution was started when business data was first stored on computers. Also, it allows users to navigate through their data in real time. We use data mining in the business community because it is supported by three technologies that are now mature
   We use to automate the process of finding predictive information in large databases. Questions that required extensive hands-on analysis can now be answered from the data. Targeted marketing is a typical example of predictive marketing. As we also use data mining on past promotional mailings. That is to identify the targets to maximize return on investment in future mailings. Other predictive problems include forecasting bankruptcy and other forms of default. And identifying segments of a population likely to respond similarly to given events.
</p>

<h2 id="para4">NATURAL LANGUAGE PROCESSING</h2>
<img src="nlp.jpg" alt="ai"  width="350" breaduth="350"/>
 <p>

  The challenging sphere of natural language processing has been a major conce
  rn in the field of computer science and artificial intelligence since the late 40’s. It encompasses the next strive forward in artificial intelligence to make computers and human interface more flexible and’ human understandable’. Various methods were adopted since its inscription like machine translation, speech recognition, e-teaching, auto tutor etc. Researchers saw it as a likely bridge between human spoken language and computers which used programming languages and binary codes. As mentioned earlier, it is still a challenging task of making a computer to understand human natural language as such. Hence, further enhancements
   and techniques will foster the demanding yet frui
   tful and futuristic computational trends.
NLP – Natural Language Processing, Semantic, Syntactic, Lexica
l, Phonology, MT – Machine Translation
The computational scheme has evolved from basic set of instructions in the fo
rm of binary codes to mnemonic instruction codes to programming languages that have prevailed intensively during the later part of twentieth century. Along that evolution came the inspirational research on making the computer understand natural human language and interact with the humans in short applying natural language processing to normal computer usage and beyond.
</p>


</body>
</html>